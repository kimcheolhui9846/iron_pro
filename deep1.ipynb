{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a93f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T02:17:45.826969Z",
     "start_time": "2025-11-10T02:17:45.801593Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # OS ê²½ë¡œ/í´ë” ìƒì„± ë“± ì‹œìŠ¤í…œ ê¸°ëŠ¥ ì‚¬ìš©\n",
    "import torch  # PyTorch ë©”ì¸ íŒ¨í‚¤ì§€\n",
    "import torch.nn as nn  # ì‹ ê²½ë§ ëª¨ë“ˆ(ë ˆì´ì–´, ì†ì‹¤ ë“±)\n",
    "from sklearn.model_selection import StratifiedKFold  # ê³„ì¸µì  K-Fold ë¶„í• \n",
    "from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œ ë°”\n",
    "from torchvision import models, transforms  # ì‚¬ì „í•™ìŠµ ëª¨ë¸/ì´ë¯¸ì§€ ë³€í™˜\n",
    "from torch.utils.data import Dataset, DataLoader  # PyTorch ë°ì´í„°ì…‹/ë¡œë”\n",
    "from datasets import load_dataset, ClassLabel, DatasetDict  # Hugging Face Datasets ìœ í‹¸\n",
    "import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚°\n",
    "from torch.amp import autocast, GradScaler  # í˜¼í•©ì •ë°€ ìë™ ìºìŠ¤íŠ¸/ìŠ¤ì¼€ì¼ëŸ¬\n",
    "import math  # ìˆ˜í•™ ìœ í‹¸\n",
    "import time  # ì‹œê°„ ì¸¡ì •\n",
    "from typing import Optional, Tuple, Dict  # íƒ€ì… íŒíŠ¸\n",
    "import torch.nn.functional as F  # í•¨ìˆ˜í˜• API (loss/activation ë“±)\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, balanced_accuracy_score, top_k_accuracy_score  # í‰ê°€ ì§€í‘œ\n",
    "from datasets import load_from_disk  # HF dataset ë””ìŠ¤í¬ ë¡œë“œ(í˜„ì¬ ì½”ë“œì—ì„  ë¯¸ì‚¬ìš©)\n",
    "from torch.autograd import Variable  # ì˜¤í† ê·¸ë¼ë“œ Variable(í˜„ PyTorchì—ì„  í…ì„œì™€ ë™ì¼, ë¯¸ì‚¬ìš©)\n",
    "from collections import Counter  # ë¼ë²¨ ì¹´ìš´íŠ¸\n",
    "\n",
    "import json, os  # JSON ì…ì¶œë ¥/OS ìœ í‹¸(ì¤‘ë³µ import but harmless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4765a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ì‚¬ìš© ë””ë°”ì´ìŠ¤ ì„ íƒ(CUDA ìš°ì„ )\n",
    "\n",
    "train_transform = transforms.Compose([  # í•™ìŠµìš© ì´ë¯¸ì§€ ì¦ê°•/ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(3/4, 4/3)),  # ëœë¤ í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomRotation(degrees=15),  # íšŒì „\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),  # ìƒ‰ìƒ/ë°ê¸°/ëŒ€ë¹„ ë³€í˜•\n",
    "    transforms.ToTensor(),  # í…ì„œ ë³€í™˜(CHW, [0,1])\n",
    "    transforms.Normalize([0.485,0.456,0.406],  # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ ì •ê·œí™”\n",
    "                         [0.229,0.224,0.225]),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3))  # ëœë¤ ì§€ìš°ê¸°(regularization)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([  # ê²€ì¦ìš©(ì•½í•œ) ì „ì²˜ë¦¬\n",
    "    transforms.Resize(256),  # ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    transforms.CenterCrop(224),  # ì¤‘ì•™ í¬ë¡­\n",
    "    transforms.ToTensor(),  # í…ì„œ ë³€í™˜\n",
    "    transforms.Normalize([0.485,0.456,0.406],  # ì •ê·œí™”\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def prepare_dataset():  # ë°ì´í„°ì…‹ ë¡œë“œ/í´ë¦°ì—…/ìŠ¤í”Œë¦¿/ë¼ë²¨ì •ë¦¬ í•¨ìˆ˜\n",
    "    dataset = load_dataset(\"Densu341/Fresh-rotten-fruit\")  # HF í—ˆë¸Œì—ì„œ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "    # 1) ë¼ë²¨ ì œê±°\n",
    "    remove_labels = [18, 20, 16, 13, 2, 5, 7, 9]  # ì œê±°í•  ë¼ë²¨ ì¸ë±ìŠ¤ ëª©ë¡\n",
    "    labels = np.array(dataset[\"train\"][\"label\"])  # ì›ë³¸ ë¼ë²¨ ë°°ì—´\n",
    "    mask = ~np.isin(labels, remove_labels)  # ì œê±°í•  ë¼ë²¨ ì œì™¸ ë§ˆìŠ¤í¬\n",
    "    clean = dataset[\"train\"].select(np.where(mask)[0])  # í•„í„°ë§ëœ ì„œë¸Œì…‹\n",
    "\n",
    "    # 2) split (ê²°ì •ì )\n",
    "    split = clean.train_test_split(test_size=0.2, seed=42)  # train/val 80:20 ê³ ì • ë¶„í• \n",
    "    train_ds, val_ds = split[\"train\"], split[\"test\"]  # ë¶„í•  ê²°ê³¼\n",
    "\n",
    "    # 3) ë¼ë²¨ ì¬ë§¤í•‘ (ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ 0..C-1)\n",
    "    uniq = sorted(set(train_ds[\"label\"]) | set(val_ds[\"label\"]))  # ì‚¬ìš©ë˜ëŠ” ë¼ë²¨ ì¸ë±ìŠ¤ ì§‘í•©\n",
    "    names = [train_ds.features[\"label\"].int2str(i) for i in uniq]  # ë¼ë²¨ ì´ë¦„ ë¦¬ìŠ¤íŠ¸\n",
    "    new_lbl = ClassLabel(num_classes=len(names), names=names)  # ìƒˆ ClassLabel ìƒì„±\n",
    "\n",
    "    def remap(example):  # ë¼ë²¨ ì¸ë±ìŠ¤ë¥¼ ìƒˆ ì¸ë±ìŠ¤ë¡œ ì¬ë§¤í•‘\n",
    "        name = train_ds.features[\"label\"].int2str(example[\"label\"])  # ê¸°ì¡´ ì¸ë±ìŠ¤â†’ì´ë¦„\n",
    "        example[\"label\"] = names.index(name)  # ì´ë¦„â†’ìƒˆ ì¸ë±ìŠ¤\n",
    "        return example\n",
    "\n",
    "    train_ds = train_ds.map(remap, num_proc=os.cpu_count()//2,  # ë³‘ë ¬ ë§µ ì ìš©(ìºì‹œ ì‚¬ìš©)\n",
    "                            load_from_cache_file=True, desc=\"Remap train\")\n",
    "    val_ds   = val_ds.map(remap,   num_proc=os.cpu_count()//2,\n",
    "                            load_from_cache_file=True, desc=\"Remap val\")\n",
    "\n",
    "    train_ds = train_ds.cast_column(\"label\", new_lbl)  # ë¼ë²¨ ìŠ¤í‚¤ë§ˆë¥¼ ìƒˆ ClassLabelë¡œ ìºìŠ¤íŒ…\n",
    "    val_ds   = val_ds.cast_column(\"label\",  new_lbl)\n",
    "\n",
    "    # 4) RGB í†µì¼ (ê²°ì •ì )\n",
    "    def to_rgb(example):  # ë¹„-RGB ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜\n",
    "        img = example[\"image\"]  # PIL ì´ë¯¸ì§€\n",
    "        if img.mode != \"RGB\":  # ëª¨ë“œê°€ RGBê°€ ì•„ë‹ˆë©´\n",
    "            img = img.convert(\"RGB\")  # RGB ë³€í™˜\n",
    "        example[\"image\"] = img  # êµì²´\n",
    "        return example\n",
    "\n",
    "    train_ds = train_ds.map(to_rgb, num_proc=os.cpu_count()//2,  # RGB í†µì¼(train)\n",
    "                            load_from_cache_file=True, desc=\"RGB train\")\n",
    "    val_ds   = val_ds.map(to_rgb,   num_proc=os.cpu_count()//2,  # RGB í†µì¼(val)\n",
    "                            load_from_cache_file=True, desc=\"RGB val\")\n",
    "\n",
    "    # âœ… ì—¬ê¸°ì„œ ë! set_transform ì•ˆ ì”€\n",
    "    return DatasetDict({\"train\": train_ds, \"test\": val_ds})  # ìµœì¢… DatasetDict ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset ë˜í¼\n",
    "# --------------------------------------------------\n",
    "class FruitHFDataset(Dataset):  # HF Datasetì„ PyTorch Datasetìœ¼ë¡œ ê°ì‹¸ëŠ” ë˜í¼\n",
    "    def __init__(self, hf_dataset, transform=None):  # HF datasetê³¼ transform ì£¼ì…\n",
    "        self.ds = hf_dataset  # ë‚´ë¶€ ì°¸ì¡°\n",
    "        self.tf = transform  # ë³€í™˜ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "    def __len__(self):  # ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):  # ì¸ë±ìŠ¤ë¡œ ìƒ˜í”Œ ì ‘ê·¼\n",
    "        item = self.ds[idx]            # image: PIL.Image, label: int\n",
    "        img  = item[\"image\"]  # ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "        if self.tf is not None:  # ë³€í™˜ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´\n",
    "            img = self.tf(img)         # Tensor(C,H,W)ë¡œ ë³€í™˜/ì¦ê°•\n",
    "        label = item[\"label\"]  # ë¼ë²¨ ì¶”ì¶œ\n",
    "        # long ë³´ì¥\n",
    "        import torch  # ì§€ì—­ import (ì›ë³¸ ì½”ë“œ ìœ ì§€)\n",
    "        if not torch.is_tensor(label):  # ë¼ë²¨ì´ í…ì„œê°€ ì•„ë‹ˆë©´\n",
    "            import torch  # ì§€ì—­ import (ì›ë³¸ ì½”ë“œ ìœ ì§€)\n",
    "            label = torch.tensor(label, dtype=torch.long)  # LongTensorë¡œ ë³€í™˜\n",
    "        else:\n",
    "            label = label.to(dtype=torch.long)  # dtype ë³´ì •\n",
    "        return img, label  # (ì´ë¯¸ì§€ í…ì„œ, ë¼ë²¨ í…ì„œ) ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì½”ë“œ cmtê¸°ë°˜ cnn+t     \n",
    "# ------------------------------------------------------------\n",
    "class DropPath(nn.Module):  # Stochastic Depth êµ¬í˜„(ìƒ˜í”Œë³„ ê²½ë¡œ ë“œë¡­)\n",
    "    \"\"\" per-sample DropPath (Stochastic Depth) \"\"\"\n",
    "    def __init__(self, drop_prob: float = 0.0):  # ë“œë¡­ í™•ë¥ \n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)  # floatë¡œ ë³´ê´€\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        if self.drop_prob == 0.0 or not self.training:  # í•™ìŠµ ì•„ë‹ ë•Œ/í™•ë¥  0ì´ë©´ íŒ¨ìŠ¤\n",
    "            return x\n",
    "        keep_prob = 1.0 - self.drop_prob  # ìœ ì§€ í™•ë¥ \n",
    "        # x: (B, ...)\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # ë°°ì¹˜ ì°¨ì›ë§Œ ë‚œìˆ˜ ìƒì„±\n",
    "        random_tensor = x.new_empty(shape).bernoulli_(keep_prob)  # ë² ë¥´ëˆ„ì´ ìƒ˜í”Œ\n",
    "        return x.div(keep_prob) * random_tensor  # ìŠ¤ì¼€ì¼ ë³´ì • í›„ ë§ˆìŠ¤í‚¹\n",
    "\n",
    "class DepthwiseConv2d(nn.Module):  # ì±„ë„ë³„(depthwise) ì»¨ë³¼ë£¨ì…˜\n",
    "    def __init__(self, channels, k=3, s=1, p=1, bias=False):  # í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(channels, channels, k, s, p, groups=channels, bias=bias)  # groups=channels\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        return self.dw(x)\n",
    "\n",
    "class ConvBNGELU(nn.Module):  # Convâ†’BNâ†’GELU ë¸”ë¡\n",
    "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)  # í•©ì„±ê³±\n",
    "        self.bn   = nn.BatchNorm2d(out_ch, eps=1e-5, momentum=0.1)  # ë°°ì¹˜ì •ê·œí™”\n",
    "        self.act  = nn.GELU()  # í™œì„±í™”\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        return self.act(self.bn(self.conv(x)))  # Convâ†’BNâ†’GELU ìˆœì„œ\n",
    "\n",
    "class ConvStage(nn.Module):  # ë‹¤ìš´ìƒ˜í”Œ í¬í•¨í•œ Conv ìŠ¤í…Œì´ì§€\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.ds   = ConvBNGELU(in_ch, out_ch, k=3, s=2, p=1)   # s=2ë¡œ ë‹¤ìš´ìƒ˜í”Œ\n",
    "        self.body = ConvBNGELU(out_ch, out_ch, k=3, s=1, p=1)  # ë³¸ì²´ ë¸”ë¡\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        x = self.ds(x)  # ë‹¤ìš´ìƒ˜í”Œ\n",
    "        x = self.body(x)  # íŠ¹ì§• ì¶”ì¶œ\n",
    "        return x\n",
    "    \n",
    "class LPU(nn.Module):  # Local Perception Unit: ì§€ì—­ DWConv+BN+GELU\n",
    "    \"\"\" Local Perception Unit: 3x3 depthwise â†’ GELU â†’ BN (ì±„ë„ ë³´ì¡´) \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.dw  = DepthwiseConv2d(channels, k=3, s=1, p=1, bias=False)  # ê¹Šì´ë³„ í•©ì„±ê³±\n",
    "        self.bn  = nn.BatchNorm2d(channels, eps=1e-5, momentum=0.1)  # BN\n",
    "        self.act = nn.GELU()  # GELU\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        x = self.dw(x)  # DWConv\n",
    "        x = self.bn(x)  # ì •ê·œí™”\n",
    "        x = self.act(x)  # í™œì„±í™”\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):  # Transformer FFN ìœ ì‚¬ MLP\n",
    "    def __init__(self, dim, mlp_ratio=3.0, drop=0.1):\n",
    "        super().__init__()\n",
    "        hidden = int(dim * mlp_ratio)  # ìˆ¨ê²¨ì§„ ì°¨ì› ê³„ì‚°\n",
    "        self.fc1 = nn.Linear(dim, hidden)  # ì²« FC\n",
    "        self.act = nn.GELU()  # í™œì„±í™”\n",
    "        self.fc2 = nn.Linear(hidden, dim)  # ë³µê·€ FC\n",
    "        self.drop = nn.Dropout(drop)  # ë“œë¡­ì•„ì›ƒ\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        x = self.fc1(x); x = self.act(x); x = self.drop(x)  # FC1â†’í™œì„±â†’ë“œë¡­\n",
    "        x = self.fc2(x); x = self.drop(x)  # FC2â†’ë“œë¡­\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):  # MSA+MLP ë¸”ë¡(LN/DropPath í¬í•¨)\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=3.0, attn_drop=0.0, proj_drop=0.1, drop_path=0.0): #drop_pathëŠ” ì—í¬í¬ ëŠ˜ì–´ë‚˜ë©´ ëŠ˜ë¦¬ì‚¼\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6) #1e-5 ~ 1e-7 ì‚¬ì´ ê°’  # ì–´í…ì…˜ ì „ ì •ê·œí™”\n",
    "        self.attn  = nn.MultiheadAttention(dim, num_heads, dropout=attn_drop, batch_first=True)  # ë©€í‹°í—¤ë“œ ì–´í…ì…˜\n",
    "        self.drop1 = nn.Dropout(proj_drop)  # ì–´í…ì…˜ ì¶œë ¥ ë“œë¡­ì•„ì›ƒ\n",
    "        self.dp1   = DropPath(drop_path)  # ìŠ¤í† ìºìŠ¤í‹± ê¹Šì´\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)  # MLP ì „ ì •ê·œí™”\n",
    "        self.mlp   = MLP(dim, mlp_ratio=mlp_ratio, drop=proj_drop)  # FFN\n",
    "        self.dp2   = DropPath(drop_path)  # ìŠ¤í† ìºìŠ¤í‹± ê¹Šì´\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        # x: (B, N, C)\n",
    "        y, _ = self.attn(self.norm1(x), self.norm1(x), self.norm1(x), need_weights=False)  # self-attention\n",
    "        x = x + self.dp1(self.drop1(y))  # ì”ì°¨ ì—°ê²° + ë“œë¡­ê²½ë¡œ\n",
    "        x = x + self.dp2(self.mlp(self.norm2(x)))  # LNâ†’MLPâ†’ì”ì°¨\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "class CMTClassifier(nn.Module):  # CNN+Transformer ê²°í•© ë¶„ë¥˜ê¸°\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,  # í´ë˜ìŠ¤ ìˆ˜\n",
    "        # CNN channels\n",
    "        stem_channels: int = 64,  # stem ì¶œë ¥ ì±„ë„\n",
    "        c_stage1: int = 96,  # stage1 ì±„ë„\n",
    "        c_stage2: int = 128,  # stage2 ì±„ë„\n",
    "        c_stage3: int = 160,  # stage3 ì±„ë„\n",
    "        # Transformer dims/heads/depths\n",
    "        t_dim1: int = 256,  t_heads1: int = 4,  t_depth1: int = 3,  t_mlp1: float = 3.0,  # 14x14 ìŠ¤í…Œì´ì§€ ì„¤ì •\n",
    "        t_dim2: int = 384,  t_heads2: int = 6,  t_depth2: int = 6,  t_mlp2: float = 3.5,  # 7x7 ìŠ¤í…Œì´ì§€ ì„¤ì •\n",
    "        attn_drop: float = 0.0,  # ì–´í…ì…˜ ë“œë¡­ì•„ì›ƒ\n",
    "        proj_drop: float = 0.1,  # í”„ë¡œì ì…˜ ë“œë¡­ì•„ì›ƒ\n",
    "        drop_path_rate: float = 0.0,  # ì—í­ ì§§ìœ¼ë©´ 0.0, ê¸¸ê²Œ í•™ìŠµí•˜ë©´ 0.05~0.1  # ìŠ¤í† ìºìŠ¤í‹± ê¹Šì´ ë²”ìœ„\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes  # í´ë˜ìŠ¤ ìˆ˜ ì €ì¥\n",
    "\n",
    "        # ----- CNN stem (224 -> 112) -----\n",
    "        self.stem = nn.Sequential(  # ì´ˆë°˜ ë‹¤ìš´ìƒ˜í”Œ/íŠ¹ì§• ì¶”ì¶œ\n",
    "            ConvBNGELU(3, stem_channels // 2, k=3, s=2, p=1),  # s=2ë¡œ í¬ê¸° ì ˆë°˜\n",
    "            ConvBNGELU(stem_channels // 2, stem_channels, k=3, s=1, p=1),  # ì±„ë„ í™•ì¥\n",
    "        )\n",
    "\n",
    "        # ----- CNN stages (112 -> 56 -> 28 -> 14) -----\n",
    "        self.stage1 = ConvStage(stem_channels, c_stage1)  # 112â†’56\n",
    "        self.stage2 = ConvStage(c_stage1, c_stage2)  # 56â†’28\n",
    "        self.stage3 = ConvStage(c_stage2, c_stage3)  # 28â†’14\n",
    "\n",
    "        # ----- to embed (14x14, C3 -> D1) -----\n",
    "        self.to_embed1 = nn.Conv2d(c_stage3, t_dim1, kernel_size=1, stride=1, padding=0, bias=True)  # ì±„ë„â†’ì„ë² ë”©\n",
    "\n",
    "        # ----- Stage A @14x14 : LPU â†’ Transformer(depth=t_depth1) -----\n",
    "        self.lpu1 = LPU(t_dim1)  # ì§€ì—­ ì¸ì‹ ìœ ë‹›\n",
    "        dpr1 = torch.linspace(0, drop_path_rate * 0.5, steps=t_depth1).tolist()  # ë“œë¡­íŒ¨ìŠ¤ ìŠ¤ì¼€ì¤„\n",
    "        self.trans1 = nn.Sequential(*[  # 14x14ì—ì„œ Transformer ë¸”ë¡ ìŠ¤íƒ\n",
    "            TransformerBlock(\n",
    "                dim=t_dim1, num_heads=t_heads1, mlp_ratio=t_mlp1,\n",
    "                attn_drop=attn_drop, proj_drop=proj_drop, drop_path=dpr1[i]\n",
    "            ) for i in range(t_depth1)\n",
    "        ])\n",
    "\n",
    "        # ----- down tokens: 14->7, D1->D2 -----\n",
    "        self.down_tokens = nn.Sequential(  # í† í° ë§µ ë‹¤ìš´ìƒ˜í”Œ(í•´ìƒë„â†“, ì±„ë„â†‘)\n",
    "            nn.Conv2d(t_dim1, t_dim2, kernel_size=3, stride=2, padding=1, bias=False),  # s=2\n",
    "            nn.BatchNorm2d(t_dim2, eps=1e-5, momentum=0.1),  # BN\n",
    "            nn.GELU(),  # í™œì„±í™”\n",
    "        )\n",
    "\n",
    "        # ----- Stage B @7x7 : LPU â†’ Transformer(depth=t_depth2) -----\n",
    "        self.lpu2 = LPU(t_dim2)  # 7x7 ë‹¨ê³„ LPU\n",
    "        dpr2 = torch.linspace(drop_path_rate * 0.5, drop_path_rate, steps=t_depth2).tolist()  # ë“œë¡­íŒ¨ìŠ¤ ìŠ¤ì¼€ì¤„ ìƒë°˜ë¶€\n",
    "        self.trans2 = nn.Sequential(*[  # 7x7ì—ì„œ Transformer ë¸”ë¡ ìŠ¤íƒ\n",
    "            TransformerBlock(\n",
    "                dim=t_dim2, num_heads=t_heads2, mlp_ratio=t_mlp2,\n",
    "                attn_drop=attn_drop, proj_drop=proj_drop, drop_path=dpr2[i]\n",
    "            ) for i in range(t_depth2)\n",
    "        ])\n",
    "\n",
    "        # ----- Head -----\n",
    "        self.head_norm = nn.LayerNorm(t_dim2, eps=1e-6)  # ìµœì¢… LN\n",
    "        self.fc        = nn.Linear(t_dim2, num_classes)  # ë¶„ë¥˜ê¸° FC\n",
    "\n",
    "        self.apply(self._init_weights)  # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ì ìš©\n",
    "\n",
    "    def _init_weights(self, m):  # ëª¨ë“ˆë³„ ì´ˆê¸°í™” ë°©ì‹ ì •ì˜\n",
    "        if isinstance(m, nn.Linear):  # ì„ í˜•ì¸µ\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)  # Truncated normal\n",
    "            if m.bias is not None: nn.init.constant_(m.bias, 0)  # bias 0\n",
    "        elif isinstance(m, nn.Conv2d):  # í•©ì„±ê³±\n",
    "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")  # He ì´ˆê¸°í™”\n",
    "            if m.bias is not None: nn.init.constant_(m.bias, 0)  # bias 0\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):  # ì •ê·œí™” ê³„ì¸µ\n",
    "            if hasattr(m, \"weight\") and m.weight is not None: nn.init.ones_(m.weight)  # gamma=1\n",
    "            if hasattr(m, \"bias\") and m.bias is not None:     nn.init.zeros_(m.bias)  # beta=0\n",
    "\n",
    "    def forward(self, x):  # ì „ë°© ê³„ì‚°\n",
    "        # CNN ì–•ì€ íŠ¹ì§•\n",
    "        x = self.stem(x)          # 224 -> 112ë¡œ ë‹¤ìš´ìƒ˜í”Œ + íŠ¹ì§•\n",
    "        x = self.stage1(x)        # 112 -> 56\n",
    "        x = self.stage2(x)        # 56  -> 28\n",
    "        x = self.stage3(x)        # 28  -> 14\n",
    "\n",
    "        # ì„ë² ë”©\n",
    "        x = self.to_embed1(x)     # B x D1 x 14 x 14 (ì±„ë„â†’ì„ë² ë”© ì°¨ì›)\n",
    "\n",
    "        # Stage A: LPU â†’ Transformer @14x14\n",
    "        x = self.lpu1(x)  # ì§€ì—­ ì¸ì‹\n",
    "        B, C, H, W = x.shape  # í…ì„œ ì°¨ì› ë¶„í•´\n",
    "        x = x.flatten(2).transpose(1, 2)           # B x 196 x D1 (íŒ¨ì¹˜ í† í°í™”)\n",
    "        x = self.trans1(x)  # íŠ¸ëœìŠ¤í¬ë¨¸ ì²˜ë¦¬\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)     # ë‹¤ì‹œ (B,C,H,W)ë¡œ ë³µì›\n",
    "\n",
    "        # Downsample tokens: 14 -> 7\n",
    "        x = self.down_tokens(x)                    # B x D2 x 7 x 7 (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        # Stage B: LPU â†’ Transformer @7x7\n",
    "        x = self.lpu2(x)  # ì§€ì—­ ì¸ì‹\n",
    "        B, C, H, W = x.shape  # ì°¨ì› ì¬í• ë‹¹\n",
    "        x = x.flatten(2).transpose(1, 2)           # B x 49 x D2 (í† í°)\n",
    "        x = self.trans2(x)                         # íŠ¸ëœìŠ¤í¬ë¨¸ ì²˜ë¦¬\n",
    "\n",
    "        # Head\n",
    "        x = x.mean(dim=1)                          # í† í° í‰ê·  í’€ë§(GAP)\n",
    "        x = self.head_norm(x)  # LN\n",
    "        logits = self.fc(x)  # í´ë˜ìŠ¤ë³„ ë¡œì§“\n",
    "        return logits  # ìµœì¢… ë¡œì§“ ë°˜í™˜\n",
    "# ------------------------------------------------------------    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ì‹¤í•¨ìˆ˜ í´ë˜ìŠ¤\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):  # ë©€í‹°í´ë˜ìŠ¤ Focal Loss êµ¬í˜„\n",
    "    \"\"\"\n",
    "    Multi-class Focal Loss with per-class alpha.\n",
    "    - inputs: logits (B, C)\n",
    "    - targets: int labels (B,)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\", eps=1e-8):  # í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "        super().__init__()\n",
    "        self.gamma = float(gamma)  # ë‚œì´ë„ ì¡°ì ˆ ì§€ìˆ˜\n",
    "        self.reduction = reduction  # ë¦¬ë•ì…˜ ë°©ì‹\n",
    "        self.eps = float(eps)  # ìˆ˜ì¹˜ ì•ˆì •ì„± epsilon\n",
    "\n",
    "        if alpha is not None:  # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ê°€ ì£¼ì–´ì§€ë©´\n",
    "            alpha = torch.as_tensor(alpha, dtype=torch.float32)  # í…ì„œí™”\n",
    "        self.register_buffer(\"alpha\", alpha if alpha is not None else None)  # ë²„í¼ë¡œ ë“±ë¡(ë””ë°”ì´ìŠ¤ ì´ë™ ìë™)\n",
    "\n",
    "    def forward(self, inputs, targets):  # ì…ë ¥ ë¡œì§“, ì •ë‹µ ë¼ë²¨\n",
    "        # logits -> log-prob/prob\n",
    "        log_probs = F.log_softmax(inputs, dim=1)   # (B, C) ë¡œê·¸ì†Œí”„íŠ¸ë§¥ìŠ¤\n",
    "        probs     = log_probs.exp()                # (B, C) í™•ë¥ \n",
    "\n",
    "        targets = targets.long()  # ë¼ë²¨ long ë³´ì¥\n",
    "        log_pt  = log_probs.gather(1, targets.unsqueeze(1)).squeeze(1)  # ì •ë‹µ í´ë˜ìŠ¤ ë¡œê·¸í™•ë¥ \n",
    "        pt      = probs.gather(1, targets.unsqueeze(1)).squeeze(1)      # ì •ë‹µ í´ë˜ìŠ¤ í™•ë¥ \n",
    "\n",
    "        # --- ìˆ˜ì¹˜ ì•ˆì •í™” ---\n",
    "        pt = pt.clamp(min=self.eps, max=1. - self.eps)  # í™•ë¥  í´ë¨í”„\n",
    "        # log_ptëŠ” log_softmax ê²°ê³¼ë¼ ì´ë¯¸ ì•ˆì •ì ì´ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ NaN ë°©ì§€:\n",
    "        log_pt = torch.log(pt)  # ë¡œê·¸ ì¬ê³„ì‚°\n",
    "\n",
    "        # alpha_t\n",
    "        if self.alpha is not None:  # í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´\n",
    "            alpha_t = self.alpha[targets]  # (B,)\n",
    "        else:\n",
    "            alpha_t = torch.ones_like(pt)  # ì—†ìœ¼ë©´ ê· ë“± ê°€ì¤‘\n",
    "\n",
    "        # focal term\n",
    "        focal = (1.0 - pt).pow(self.gamma)  # ì–´ë ¤ìš´ ìƒ˜í”Œ ê°€ì¤‘â†‘\n",
    "        loss  = -alpha_t * focal * log_pt  # Focal loss ê³µì‹\n",
    "\n",
    "        if self.reduction == \"mean\":  # í‰ê·  ë¦¬ë•ì…˜\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":  # í•© ë¦¬ë•ì…˜\n",
    "            return loss.sum()\n",
    "        return loss  # ë¦¬ë•ì…˜ ì—†ìŒ\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba46fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì¸\n",
    "def main():  # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ë””ë°”ì´ìŠ¤ ì¬í™•ì¸\n",
    "    print(\"device:\", device)  # ë””ë°”ì´ìŠ¤ ì¶œë ¥\n",
    "    if torch.cuda.is_available():  # CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ\n",
    "        print(torch.cuda.get_device_name(0))  # GPU ì´ë¦„ ì¶œë ¥\n",
    "\n",
    "    final_dataset = prepare_dataset()  # ë°ì´í„°ì…‹ ì¤€ë¹„(í´ë¦°/ìŠ¤í”Œë¦¿/ë¼ë²¨ì •ë¦¬)\n",
    "\n",
    "    names = final_dataset[\"train\"].features[\"label\"].names  # ë¼ë²¨ ì´ë¦„ ë¦¬ìŠ¤íŠ¸\n",
    "    save_dir = \"C:/Users/USER-PC/Desktop/deep/model_data\"  # ì €ì¥ ê²½ë¡œ\n",
    "    os.makedirs(save_dir, exist_ok=True)  # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    with open(os.path.join(save_dir, \"label_names.json\"), \"w\", encoding=\"utf-8\") as f:  # ë¼ë²¨ ì´ë¦„ ì €ì¥\n",
    "        json.dump(names, f, ensure_ascii=False)  # JSON ë¤í”„\n",
    "\n",
    "        \n",
    "    num_classes = len(final_dataset[\"train\"].features[\"label\"].names)  # í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°\n",
    "\n",
    "    # ----- class-balanced alpha (FocalLossìš©) -----\n",
    "    train_labels = [int(x) for x in final_dataset[\"train\"][\"label\"]]  # í•™ìŠµ ë¼ë²¨ ëª©ë¡\n",
    "    counts = Counter(train_labels)  # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "    class_counts = [counts[i] for i in range(num_classes)]  # ìˆœì„œëŒ€ë¡œ ì¹´ìš´íŠ¸ ë°°ì—´ ìƒì„±\n",
    "\n",
    "    beta = 0.999  # íš¨ê³¼ì  ìˆ˜ ìˆ˜ì‹ì˜ ë² íƒ€(í´ë˜ìŠ¤ ë¹ˆë„ ì¡°ì •)\n",
    "    effective_num = [1.0 - (beta ** c) for c in class_counts]  # ê° í´ë˜ìŠ¤ì˜ ìœ íš¨ ìƒ˜í”Œ ìˆ˜\n",
    "    raw_alpha = torch.tensor([(1.0 - beta) / (en if en > 0 else 1e-8)  # í´ë˜ìŠ¤ ê°€ì¤‘ ì›ì‹œê°’\n",
    "                              for en in effective_num], dtype=torch.float32)\n",
    "    alpha = (raw_alpha / raw_alpha.sum()) * num_classes  # í‰ê·  1ë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "    print(\"alpha:\", alpha.tolist())  # ê°€ì¤‘ì¹˜ ì¶œë ¥\n",
    "\n",
    "\n",
    "    EPOCHS = 5  # í•™ìŠµ epoch ìˆ˜\n",
    "    BATCH_SIZE = 128  #ë°ìŠ¤í¬íƒ‘ì€ 128ë¡œ  # ë°°ì¹˜ í¬ê¸°\n",
    "    K = 3  # K-Fold ìˆ˜\n",
    "    best_acc = 0.0  # ì „ì²´ ë² ìŠ¤íŠ¸ ì •í™•ë„\n",
    "\n",
    "    # ==== í•™ìŠµë¥ /ì •ê·œí™” í•˜ì´í¼íŒŒë¼ë¯¸í„° ====\n",
    "    LR_CNN = 5e-5          # CNN(stem, stage1~3)ìš© learning rate\n",
    "    LR_TRANS = 1e-4        # Transformer + ë¶„ë¥˜ê¸° í—¤ë“œìš© learning rate\n",
    "    WEIGHT_DECAY = 1e-4    # AdamW weight decay\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ë””ë°”ì´ìŠ¤ ì¬ì„¤ì •(ì¤‘ë³µì´ì§€ë§Œ ìœ ì§€)\n",
    "    print(\"device:\", device, flush=True)  # ë””ë°”ì´ìŠ¤ ì¶œë ¥(flush)\n",
    "    print(torch.cuda.get_device_name(0))  # GPU ì´ë¦„ ì¶œë ¥\n",
    "\n",
    "# StratifiedKFoldë¥¼ ìœ„í•´ ë¼ë²¨ ë²¡í„° ì¶”ì¶œ\n",
    "    labels  = np.asarray(final_dataset[\"train\"][\"label\"], dtype=np.int64)  # ë¼ë²¨ ë°°ì—´(np.int64)\n",
    "    indices = np.arange(len(final_dataset[\"train\"]), dtype=np.int64)  # ì¸ë±ìŠ¤ ë°°ì—´\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)  # ê³„ì¸µì  K-Fold ë¶„í• ê¸°\n",
    "\n",
    "    fold_accs = []  # foldë³„ val acc ê¸°ë¡\n",
    "    start_time = time.time()  # ì „ì²´ ì‹œì‘ ì‹œê°„\n",
    "    num_classes = len(final_dataset[\"train\"].features[\"label\"].names)  # í´ë˜ìŠ¤ ìˆ˜(ì¬í™•ì¸)\n",
    "\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(indices, labels), 1):  # ê° í´ë“œ ë°˜ë³µ\n",
    "        print(f\"\\n================ Fold {fold}/{K} ì‹œì‘ ================\")  # í´ë“œ ì‹œì‘ ë¡œê·¸\n",
    "        fold_start = time.time()  # í´ë“œ ì‹œì‘ ì‹œê°„\n",
    "\n",
    "        # --- (1) ë°ì´í„° ë¶„í•  & DataLoader ---\n",
    "        train_split = final_dataset[\"train\"].select(list(train_idx))  # í•™ìŠµ ì¸ë±ìŠ¤ ì„ íƒ(í˜„ì¬ ì•„ë˜ì—ì„œ ë¯¸í™œìš©)\n",
    "        val_split   = final_dataset[\"train\"].select(list(val_idx))  # ê²€ì¦ ì¸ë±ìŠ¤ ì„ íƒ(í˜„ì¬ ì•„ë˜ì—ì„œ ë¯¸í™œìš©)\n",
    "\n",
    "        train_ds = FruitHFDataset(final_dataset[\"train\"], transform=train_transform)  # ì „ì²´ trainì— í•™ìŠµ ë³€í™˜ ì ìš©\n",
    "        val_ds   = FruitHFDataset(final_dataset[\"test\"],  transform=val_transform)  # test splitì— ê²€ì¦ ë³€í™˜ ì ìš©\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  # í•™ìŠµìš© DataLoader\n",
    "                                num_workers=6, pin_memory=True, persistent_workers=False, prefetch_factor=2)\n",
    "        val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,  # ê²€ì¦ìš© DataLoader\n",
    "                                num_workers=6, pin_memory=True, persistent_workers=False, prefetch_factor=2)\n",
    "        \n",
    "        #ë³‘ëª©ì¸ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œì„---------------------\n",
    "        loader_start = time.time()  # ë¡œë” ì†ë„ ì¸¡ì • ì‹œì‘\n",
    "        for i, (x, y) in enumerate(train_loader):  # ë°°ì¹˜ ë°˜ë³µ\n",
    "            if i == 10:  # 10ë°°ì¹˜ê¹Œì§€ë§Œ í™•ì¸\n",
    "                break\n",
    "        print(f\"ì²« 10 batch ë¡œë”© ì‹œê°„: {time.time() - loader_start:.2f}ì´ˆ\")  # ë¡œë”© ì‹œê°„ ì¶œë ¥\n",
    "        #--------------------------------------------\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ê³ ì • ì‹œ Convolution íŠœë„ˆ í™œì„±í™”\n",
    "\n",
    "        # --- ëª¨ë¸/ì†ì‹¤/ì˜µí‹°ë§ˆì´ì € -----------------------------------------------------------------------\n",
    "        model = CMTClassifier(num_classes).to(device)  # ëª¨ë¸ ìƒì„±/ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "        criterion = FocalLoss(alpha=alpha.to(device), gamma=2.0).to(device) #ì†ì‹¤í•¨ìˆ˜ë¡œ focal loss ì‚¬ìš©í•¨  # ì†ì‹¤ í•¨ìˆ˜(Focal)\n",
    "        # ---------------- íŒŒë¼ë¯¸í„° ê·¸ë£¹ ì„¤ì • ----------------\n",
    "    cnn_modules = [\n",
    "        model.stem,\n",
    "        model.stage1,\n",
    "        model.stage2,\n",
    "        model.stage3,\n",
    "    ]\n",
    "\n",
    "    trans_modules = [\n",
    "        model.to_embed1,\n",
    "        model.lpu1,\n",
    "        model.trans1,\n",
    "        model.down_tokens,\n",
    "        model.lpu2,\n",
    "        model.trans2,\n",
    "        model.head_norm,\n",
    "        model.fc,\n",
    "    ]\n",
    "\n",
    "    cnn_params = []\n",
    "    trans_params = []\n",
    "\n",
    "    for m in cnn_modules:\n",
    "        cnn_params += list(m.parameters())\n",
    "\n",
    "    for m in trans_modules:\n",
    "        trans_params += list(m.parameters())\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": cnn_params,  \"lr\": LR_CNN},\n",
    "        {\"params\": trans_params, \"lr\": LR_TRANS},\n",
    "    ],\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "# ----------------------------------------------------ì‚¬ìš©  # ì˜µí‹°ë§ˆì´ì €\n",
    "\n",
    "    scaler = GradScaler()  # í˜¼í•©ì •ë°€ ìŠ¤ì¼€ì¼ëŸ¬(AMP)\n",
    "\n",
    "                \n",
    "    val_acc_list = []  # ì—í­ë³„ val acc ê¸°ë¡\n",
    "    val_loss_list = []  # ì—í­ë³„ val loss ê¸°ë¡\n",
    "    val_f1_list   = []  # ì—í­ë³„ macro-F1 ê¸°ë¡\n",
    "\n",
    "        # --- Epoch ë£¨í”„ ---\n",
    "    for epoch in range(1, EPOCHS+1):  # 1~EPOCHS\n",
    "            epoch_start = time.time()  # ì—í­ ì‹œì‘ ì‹œê°„\n",
    "            print(f\"\\nâ–¶ Fold {fold}/{K} | Epoch {epoch}/{EPOCHS}\")  # ì—í­ ì‹œì‘ ë¡œê·¸\n",
    "\n",
    "            # ---- [Train] ----\n",
    "            model.train()  # í•™ìŠµ ëª¨ë“œ\n",
    "            total, correct, loss_sum = 0, 0, 0.0  # í†µê³„ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "            pbar = tqdm(train_loader, desc=f\"Fold {fold} Epoch {epoch} [Train]\", ncols=100)  # ì§„í–‰ë°”\n",
    "\n",
    "            for x, y in pbar:  # ë°°ì¹˜ ë°˜ë³µ\n",
    "                x = x.to(device, non_blocking=True)  # ì…ë ¥ í…ì„œ ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "                y = y.to(device, non_blocking=True)  # ë¼ë²¨ ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)  # ê·¸ë˜ë””ì–¸íŠ¸ 0 ì´ˆê¸°í™”\n",
    "\n",
    "                with autocast(\"cuda\"):  # AMP ìë™ ìºìŠ¤íŠ¸(CUDA ì „ìš©)\n",
    "                    out  = model(x)  # ëª¨ë¸ ì „ë°© ê³„ì‚°\n",
    "                    loss = criterion(out, y)  # Focal loss ê³„ì‚°\n",
    "\n",
    "                # (ì„ íƒ) gradient clippingì„ ì›í•œë‹¤ë©´: scaler.unscale_ í›„ clip\n",
    "                # scaler.unscale_(optimizer)\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                scaler.scale(loss).backward()  # ìŠ¤ì¼€ì¼ëœ backward\n",
    "                scaler.step(optimizer)  # ì˜µí‹°ë§ˆì´ì € ìŠ¤í…(ìŠ¤ì¼€ì¼ ê³ ë ¤)\n",
    "                scaler.update()  # ìŠ¤ì¼€ì¼ ì—…ë°ì´íŠ¸\n",
    "\n",
    "                bs = x.size(0)  # ë°°ì¹˜ í¬ê¸°\n",
    "                loss_sum += loss.item() * bs  # ì†ì‹¤ ëˆ„ì (ìƒ˜í”Œìˆ˜ ê°€ì¤‘)\n",
    "                correct  += (out.argmax(1) == y).sum().item()  # ì •ë‹µ ì¹´ìš´íŠ¸\n",
    "                total    += bs  # ìƒ˜í”Œ ìˆ˜ ëˆ„ì \n",
    "\n",
    "            tr_acc  = correct / max(1, total)  # í•™ìŠµ ì •í™•ë„\n",
    "            tr_loss = loss_sum / max(1, total)  # í•™ìŠµ ì†ì‹¤ í‰ê· \n",
    "            print(f\"Train â–¶ acc: {tr_acc:.4f} | loss: {tr_loss:.4f}\")  # í•™ìŠµ í†µê³„ ì¶œë ¥\n",
    "                # ---- [Validation] ----\n",
    "            model.eval()  # í‰ê°€ ëª¨ë“œ\n",
    "            v_total, v_correct, v_loss_sum = 0, 0, 0.0  # ê²€ì¦ í†µê³„ ì´ˆê¸°í™”\n",
    "            \n",
    "\n",
    "            all_preds, all_labels, all_logits = [], [], []  # ì˜ˆì¸¡/ì •ë‹µ/ë¡œì§“ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "            with torch.inference_mode():  # no_grad + ì¶”ê°€ ìµœì í™”\n",
    "                 for x, y in tqdm(val_loader, desc=f\"Fold {fold} Epoch {epoch} [Val]\", ncols=100):  # ê²€ì¦ ë°˜ë³µ\n",
    "                    x = x.to(device, non_blocking=True)  # ì…ë ¥ ì´ë™\n",
    "                    y = y.to(device, non_blocking=True)  # ë¼ë²¨ ì´ë™\n",
    "\n",
    "                    with autocast(\"cuda\"):  # AMP í‰ê°€\n",
    "                        out  = model(x)  # ì „ë°© ê³„ì‚°\n",
    "                        v_loss = criterion(out, y)  # ì†ì‹¤ ê³„ì‚°\n",
    "\n",
    "                    bs = x.size(0)  # ë°°ì¹˜ í¬ê¸°\n",
    "                    v_loss_sum += v_loss.item() * bs  # ì†ì‹¤ ëˆ„ì \n",
    "                    preds = out.argmax(1)  # ì˜ˆì¸¡ ë¼ë²¨\n",
    "                    v_correct += (preds == y).sum().item()  # ì •ë‹µ ì¹´ìš´íŠ¸\n",
    "                    v_total   += bs  # ìƒ˜í”Œ ìˆ˜ ëˆ„ì \n",
    "\n",
    "                    # ğŸ”¹ ì˜ˆì¸¡/ì •ë‹µ/ë¡œì§“ ì €ì¥ (CPUë¡œ ë³€í™˜)\n",
    "                    all_preds.extend(preds.detach().cpu().numpy())  # ì˜ˆì¸¡ ìˆ˜ì§‘\n",
    "                    all_labels.extend(y.detach().cpu().numpy())  # ì •ë‹µ ìˆ˜ì§‘\n",
    "                    all_logits.append(out.detach().cpu().numpy())  # ë¡œì§“ ìˆ˜ì§‘\n",
    "\n",
    "            va_acc  = v_correct / max(1, v_total)  # ê²€ì¦ ì •í™•ë„\n",
    "            va_loss = v_loss_sum / max(1, v_total)  # ê²€ì¦ ì†ì‹¤ í‰ê· \n",
    "            all_logits = np.concatenate(all_logits, axis=0)  # ë¡œì§“ í•©ì¹˜ê¸°\n",
    "            va_f1   = f1_score(all_labels, all_preds, average=\"macro\")  # ë§¤í¬ë¡œ F1\n",
    "            va_bal  = balanced_accuracy_score(all_labels, all_preds)  # ê· í˜• ì •í™•ë„\n",
    "\n",
    "            try:\n",
    "                va_top2 = top_k_accuracy_score(all_labels, all_logits, k=2, labels=np.arange(all_logits.shape[1]))  # top-2\n",
    "                va_top3 = top_k_accuracy_score(all_labels, all_logits, k=3, labels=np.arange(all_logits.shape[1]))  # top-3\n",
    "            except Exception:\n",
    "                va_top2 = va_top3 = None  # ì˜ˆì™¸ ì‹œ None\n",
    "\n",
    "    \n",
    "            val_acc_list.append(va_acc)  # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            val_loss_list.append(va_loss)  # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            val_f1_list.append(va_f1)  # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            print(f\"Val â–¶ acc: {va_acc:.4f} | f1: {va_f1:.4f} | bal_acc: {va_bal:.4f} | loss: {va_loss:.4f}\")  # ê²€ì¦ ë¡œê·¸\n",
    "            if va_top2 is not None:\n",
    "                print(f\"      top-2: {va_top2:.4f} | top-3: {va_top3:.4f}\")  # top-k ì¶œë ¥\n",
    "\n",
    "            \n",
    "            save_dir = \"C:/Users/USER-PC/Desktop/deep/model_data\"  # ì €ì¥ í´ë”\n",
    "            os.makedirs(save_dir, exist_ok=True)  # í´ë” ìƒì„±\n",
    "            \n",
    "            if va_acc > best_acc + 1e-6:  # ì „ì²´ ë² ìŠ¤íŠ¸ ê°±ì‹  ì¡°ê±´(ë¶€ë™ì†Œìˆ˜ ë³´í˜¸)\n",
    "                best_acc = va_acc  # ë² ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸\n",
    "                save_path = os.path.join(save_dir, f\"best_model_fold{fold}.pt\")  # ê²½ë¡œ\n",
    "                torch.save(model.state_dict(), save_path)  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
    "                print(f\"New best model saved! (fold={fold}, acc={best_acc:.4f})\")  # ì €ì¥ ë¡œê·¸\n",
    "\n",
    "\n",
    "            epoch_time = time.time() - epoch_start  # ì—í­ ì†Œìš” ì‹œê°„\n",
    "            print(f\"Epoch {epoch} ì™„ë£Œ (ì†Œìš”ì‹œê°„: {epoch_time:.2f}ì´ˆ)\")  # ì—í­ ì™„ë£Œ ë¡œê·¸\n",
    "\n",
    "        # --- (4) Fold ì¢…ë£Œ ì²˜ë¦¬ (fold â€˜ì•ˆâ€™) ---\n",
    "    fold_time = time.time() - fold_start  # í´ë“œ ì†Œìš” ì‹œê°„\n",
    "    print(f\"âœ… Fold {fold} ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {fold_time/60:.2f}ë¶„)\")  # í´ë“œ ì™„ë£Œ ë¡œê·¸\n",
    "    fold_accs.append(val_acc_list)  # í´ë“œë³„ val acc ë¦¬ìŠ¤íŠ¸ ì €ì¥\n",
    "\n",
    "    # --- (5) ì „ì²´ ìš”ì•½ (fold â€˜ë°”ê¹¥â€™) ---\n",
    "    total_time = time.time() - start_time  # ì´ í•™ìŠµ ì‹œê°„\n",
    "    print(f\"\\n================ í•™ìŠµì¢…ë£Œ ì´ ì†Œìš”ì‹œê°„: {total_time/60:.2f}ë¶„ ================\")  # ì´ ì†Œìš” ë¡œê·¸\n",
    "\n",
    "    print(\"\\n===== K-Fold ê²°ê³¼ ìš”ì•½ =====\")  # ìš”ì•½ í‘œì œ\n",
    "    best_accs = [max(a) if isinstance(a, list) else a for a in fold_accs]  # ê° í´ë“œ ìµœê³  ì„±ëŠ¥ ì¶”ì¶œ\n",
    "    for i, acc in enumerate(best_accs, start=1):  # í´ë“œë³„ ì¶œë ¥\n",
    "        print(f\"Fold {i:>2} | ìµœê³  val_acc = {acc:.4f}\")\n",
    "    mean_acc = sum(best_accs) / len(best_accs)  # í‰ê·  ì •í™•ë„\n",
    "    print(f\"í‰ê·  val_acc = {mean_acc:.4f}\")  # í‰ê·  ì¶œë ¥\n",
    "\n",
    "    torch.save(model.state_dict(), \"best_model.pt\")  # ë§ˆì§€ë§‰ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  # ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸\n",
    "    torch.multiprocessing.set_start_method(\"spawn\", force=True)  # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ë²• ì§€ì •\n",
    "    main()  # ë©”ì¸ ì‹¤í–‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
